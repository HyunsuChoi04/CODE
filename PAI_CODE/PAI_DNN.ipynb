{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file1 = '/content/drive/MyDrive/PAI_sound.wav'\n",
    "midi_file2 = '/content/drive/MyDrive/backgroundsound.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_note1 = 60\n",
    "num_note2 = 120\n",
    "sec = 2\n",
    "audio = []\n",
    "inst = []\n",
    "\n",
    "for inst_idx, note in itertools.product(range(1), range(num_note1)):\n",
    "    offset = (note*sec)\n",
    "    #print('instrunment: {}, note: {}, offset: {}'.format(0, note, offset))\n",
    "    y, sr = librosa.load(midi_file1, sr=None, offset=offset, duration=2.0)\n",
    "    audio.append(y)\n",
    "    inst.append(0)\n",
    "\n",
    "for inst_idx, note in itertools.product(range(1), range(num_note2)):\n",
    "    offset = (note*sec)\n",
    "    #print('instrunment: {}, note: {}, offset: {}'.format(1, note, offset))\n",
    "    y, sr = librosa.load(midi_file2, sr=None, offset=offset, duration=2.0)\n",
    "    audio.append(y)\n",
    "    inst.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_np = np.array(audio_mfcc, np.float32)\n",
    "inst_np = np.array(inst, np.int16)\n",
    "\n",
    "print(mfcc_np.shape, inst_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_np = mfcc_np.reshape((420), 20 * 173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(mfcc_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "mfcc_np = np.array(audio_mfcc, np.float32)\n",
    "mfcc_array = np.expand_dims(mfcc_np, -1)\n",
    "inst_cat = to_categorical(inst_np)\n",
    "\n",
    "train_x, test_x, train_y, test_y  = train_test_split(mfcc_array, inst_cat, test_size=0.2)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "def model_build():\n",
    "    model = Sequential()\n",
    "    input = Input(shape=(20, 173, 1))\n",
    "    output = Conv2D(64, 3, strides=1, padding='same', activation='relu')(input)\n",
    "    output = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(output)\n",
    "\n",
    "    output = Conv2D(128, 3, strides=1, padding='same', activation='relu')(output)\n",
    "    output = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(output)\n",
    "\n",
    "    output = Conv2D(256, 3, strides=1, padding='same', activation='relu')(output)\n",
    "    output = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(output)\n",
    "\n",
    "    output = Conv2D(512, 3, strides=1, padding='same', activation='relu')(output)\n",
    "    output = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(output)\n",
    "\n",
    "    output = Flatten()(output)\n",
    "    output = Dense(256, activation='relu')(output)\n",
    "    output = Dense(128, activation='relu')(output)\n",
    "    output = Dense(64, activation='relu')(output)\n",
    "    output = Dense(2, activation='sigmoid')(output)\n",
    "\n",
    "    model = Model(inputs=[input], outputs=output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, epochs=70, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history_dict):\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, (len(loss) + 1))\n",
    "    fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "    ax1.plot(epochs, val_loss, 'r:', label='val_loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "\n",
    "    acc = history_dict['acc']\n",
    "    val_acc = history_dict['val_acc']\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.plot(epochs, acc, 'b--', label='train_accuracy')\n",
    "    ax2.plot(epochs, val_acc, 'r:', label='val_accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y)\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#model.save('PAI_Model_V2(0.052, 0.976).h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
